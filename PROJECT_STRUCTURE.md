# ðŸ“ Project Structure & File Guide

## Directory Layout

```
college-sports-prediction/
â”‚
â”œâ”€â”€ ðŸ“„ requirements.txt              # Python dependencies
â”œâ”€â”€ ðŸ“„ README.md                     # Complete documentation
â”œâ”€â”€ ðŸ“„ QUICKSTART.md                 # Quick start guide
â”œâ”€â”€ ðŸ“„ PROJECT_STRUCTURE.md          # This file
â”œâ”€â”€ ðŸ“„ setup.sh                      # Automated setup script
â”œâ”€â”€ ðŸ“„ .env.example                  # Environment variable template
â”‚
â”œâ”€â”€ ðŸ utils.py                      # Core utilities (1,000+ lines)
â”œâ”€â”€ ðŸ train_model.py                # Model training (800+ lines)
â”œâ”€â”€ ðŸ main.py                       # Streamlit app (600+ lines)
â”‚
â””â”€â”€ ðŸ“‚ model/                        # Trained models directory
    â”œâ”€â”€ college_basketball_xgb.pkl
    â”œâ”€â”€ college_football_xgb.pkl
    â”œâ”€â”€ college_basketball_feature_importance.csv
    â””â”€â”€ college_football_feature_importance.csv
```

---

## ðŸ“„ File Descriptions

### Core Application Files

#### `utils.py` - Data Handling & Feature Engineering
**Purpose**: Core utility functions for data processing

**Key Functions**:
- `fetch_data_from_srating()` - API interaction with error handling
- `calculate_elo()` - Dynamic ELO rating system (800+ lines of implementation)
- `create_features()` - Master feature engineering pipeline
- `calculate_rolling_stats()` - Rolling average calculations
- `calculate_rest_days()` - Team fatigue metrics
- `prepare_prediction_features()` - Single game feature prep

**Dependencies**: pandas, numpy, requests

**When to Edit**:
- Adding new features
- Modifying ELO parameters
- Changing rolling window sizes
- Adding new data sources

---

#### `train_model.py` - Model Training Pipeline
**Purpose**: Orchestrates the complete model training workflow

**Key Functions**:
- `prepare_training_data()` - Complete data prep pipeline
- `fetch_historical_games()` - API data fetching for date ranges
- `clean_game_data()` - Data standardization and cleaning
- `train_and_save_model()` - XGBoost training and persistence
- `generate_mock_data()` - Synthetic data for testing

**Dependencies**: scikit-learn, xgboost, joblib, pandas, numpy

**When to Edit**:
- Changing model architecture
- Tuning hyperparameters
- Adjusting training/test split
- Modifying cross-validation

**Usage**:
```bash
python train_model.py
```

---

#### `main.py` - Streamlit Web Application
**Purpose**: Interactive UI for generating and viewing predictions

**Key Functions**:
- `load_model()` - Cached model loading (@st.cache_resource)
- `fetch_todays_games()` - Get games for prediction date
- `generate_predictions()` - Apply model to generate probabilities
- `display_predictions_table()` - Formatted prediction display
- `display_high_confidence_picks()` - Highlight best bets
- `display_statistics()` - Summary metrics

**Dependencies**: streamlit, pandas, numpy, joblib

**When to Edit**:
- Changing UI layout
- Adding new visualizations
- Modifying prediction display
- Adding filters or controls

**Usage**:
```bash
streamlit run main.py
```

---

### Configuration Files

#### `requirements.txt` - Python Dependencies
**Contents**:
```
pandas>=2.0.0          # Data manipulation
numpy>=1.24.0          # Numerical computing
requests>=2.31.0       # API calls
scikit-learn>=1.3.0    # ML utilities
xgboost>=2.0.0         # Gradient boosting
joblib>=1.3.0          # Model persistence
streamlit>=1.29.0      # Web UI
python-dotenv>=1.0.0   # Environment variables
```

**When to Update**:
- Adding new Python libraries
- Upgrading package versions
- Resolving dependency conflicts

---

#### `.env.example` - Environment Template
**Purpose**: Template for required environment variables

**Contents**:
```bash
SRATING_API_KEY=your-api-key-here
```

**Setup**:
```bash
cp .env.example .env
# Edit .env with your actual API key
```

---

### Documentation Files

#### `README.md` - Complete Documentation
**Sections**:
- Features overview
- Installation guide
- Usage instructions
- Model explanation
- API documentation
- Troubleshooting
- Advanced configuration

**Length**: 500+ lines

---

#### `QUICKSTART.md` - Quick Start Guide
**Purpose**: Get running in <5 minutes

**Sections**:
- 3-step setup
- Basic usage
- Understanding output
- Common issues
- Tips and tricks

**Length**: 200+ lines

---

#### `setup.sh` - Automated Setup Script
**Purpose**: One-command setup

**What it does**:
1. Checks Python installation
2. Installs dependencies
3. Verifies API key (optional)
4. Offers to train models
5. Provides next steps

**Usage**:
```bash
bash setup.sh
```

---

## ðŸ“‚ Model Directory

### Generated Files

#### `college_basketball_xgb.pkl`
- Trained XGBoost model for CBB
- Size: ~400-500 KB
- Binary format (pickle)
- Contains 200 decision trees

#### `college_football_xgb.pkl`
- Trained XGBoost model for CFB
- Size: ~400-500 KB
- Binary format (pickle)
- Contains 200 decision trees

#### `*_feature_importance.csv`
- Feature rankings by importance
- Format: feature name, importance score
- Used for model interpretation
- Helps identify key predictors

---

## ðŸ”„ Workflow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Data Pipeline                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. fetch_data_from_srating()                       â”‚
â”‚     â””â”€ API call with authentication                 â”‚
â”‚     â””â”€ Error handling & validation                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. calculate_elo()                                 â”‚
â”‚     â””â”€ Sort games chronologically                   â”‚
â”‚     â””â”€ Update ratings after each game               â”‚
â”‚     â””â”€ Store pre-game ELO values                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. create_features()                               â”‚
â”‚     â””â”€ Calculate rolling statistics                 â”‚
â”‚     â””â”€ Compute rest days                            â”‚
â”‚     â””â”€ Add momentum indicators                      â”‚
â”‚     â””â”€ Engineer domain features                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. train_and_save_model()                          â”‚
â”‚     â””â”€ Split train/test data                        â”‚
â”‚     â””â”€ Train XGBoost classifier                     â”‚
â”‚     â””â”€ Evaluate performance                         â”‚
â”‚     â””â”€ Save model to disk                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. Streamlit Application                           â”‚
â”‚     â””â”€ Load trained model                           â”‚
â”‚     â””â”€ Fetch today's games                          â”‚
â”‚     â””â”€ Generate predictions                         â”‚
â”‚     â””â”€ Display results                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸŽ¯ Feature Engineering Pipeline

```
Raw Game Data
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Clean Data     â”‚
â”‚  - Dates        â”‚
â”‚  - Scores       â”‚
â”‚  - Teams        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ELO Ratings    â”‚
â”‚  - Home ELO     â”‚
â”‚  - Away ELO     â”‚
â”‚  - Differential â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Rolling Stats  â”‚
â”‚  - 3 games      â”‚
â”‚  - 5 games      â”‚
â”‚  - 10 games     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Context        â”‚
â”‚  - Rest days    â”‚
â”‚  - Momentum     â”‚
â”‚  - Streaks      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    Feature Matrix
    (19 features)
```

---

## ðŸ“Š Data Flow

### Training Phase
```
Historical Games (API/Mock)
    â†’ Clean & Standardize
    â†’ Calculate ELO
    â†’ Engineer Features
    â†’ Split Train/Test
    â†’ Train XGBoost
    â†’ Evaluate & Save
```

### Prediction Phase
```
Today's Games (API/Mock)
    â†’ Load Trained Model
    â†’ Prepare Features
    â†’ Generate Probabilities
    â†’ Calculate Confidence
    â†’ Display Results
```

---

## ðŸ”§ Customization Points

### Easy Customizations
1. **ELO K-Factor**: Line 106 in utils.py
2. **Rolling Windows**: Line 157 in utils.py
3. **Model Parameters**: Line 235 in train_model.py
4. **UI Layout**: Lines 380-450 in main.py

### Medium Customizations
1. **Add New Features**: Modify `create_features()` in utils.py
2. **Change Model Type**: Replace XGBoost in train_model.py
3. **Add Data Sources**: Extend API calls in utils.py

### Advanced Customizations
1. **Multi-Model Ensemble**: Combine multiple algorithms
2. **Real-Time Updates**: Add live score tracking
3. **Player Statistics**: Individual player features
4. **Betting Integration**: Add odds and line data

---

## ðŸ§ª Testing Strategy

### Unit Tests (Future Enhancement)
```python
# test_utils.py
def test_calculate_elo():
    # Test ELO calculation
    pass

def test_create_features():
    # Test feature engineering
    pass
```

### Integration Tests
```python
# test_pipeline.py
def test_full_pipeline():
    # Test end-to-end workflow
    pass
```

### Manual Testing
1. Run with mock data
2. Verify predictions are reasonable
3. Check feature importance makes sense
4. Test UI responsiveness

---

## ðŸ“ˆ Performance Optimization

### Current Optimizations
- `@st.cache_resource` for model loading
- `@lru_cache` for repeated calculations
- Vectorized operations with numpy/pandas

### Future Optimizations
- Database caching for historical data
- Parallel model training
- GPU acceleration for XGBoost
- API request batching

---

## ðŸ” Security Considerations

### Current Implementation
- API key via environment variable
- No hardcoded credentials
- Input validation on API responses

### Production Recommendations
- Use secrets management service
- Add rate limiting
- Implement API key rotation
- Add user authentication
- Enable HTTPS only

---

## ðŸ“ Version Control

### Recommended .gitignore
```
# Environment
.env
__pycache__/
*.pyc

# Models
model/*.pkl

# Data
data/
*.csv

# IDE
.vscode/
.idea/
```

---

## ðŸš€ Deployment Options

### Local
```bash
streamlit run main.py
```

### Streamlit Cloud
1. Push to GitHub
2. Connect to Streamlit Cloud
3. Add secrets (API key)
4. Deploy!

### Docker
```dockerfile
FROM python:3.9
COPY . /app
WORKDIR /app
RUN pip install -r requirements.txt
CMD streamlit run main.py
```

### Heroku / AWS / GCP
- Include Procfile
- Set environment variables
- Configure port binding

---

**Need Help?** Check README.md for detailed documentation!
